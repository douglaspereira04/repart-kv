#!/usr/bin/env Rscript
#
# Generate charts from CSV metrics files.
#
# This script reads CSV files generated by the workload executor and creates
# charts showing operations per second vs number of workers, with separate
# lines for each storage type.
#
# Usage:
#   Rscript generate_charts.R [input_path] [output_path]
#
# Arguments:
#   input_path:  Directory containing CSV files (default: current directory)
#   output_path: Directory to save charts (default: ./charts)

suppressPackageStartupMessages({
  library(ggplot2)
  library(dplyr)
  library(stringr)
  library(scales)
})

# Parse command line arguments
args <- commandArgs(trailingOnly = TRUE)
input_path <- if (length(args) >= 1) args[1] else "."
output_path <- if (length(args) >= 2) args[2] else "./charts"

# Validate input path
if (!dir.exists(input_path)) {
  stop(paste("Error: Input path '", input_path, "' is not a directory", sep = ""))
}

# Find all CSV files
csv_files <- list.files(path = input_path, pattern = "\\.csv$", full.names = TRUE)

if (length(csv_files) == 0) {
  warning(paste("Warning: No CSV files found in '", input_path, "'", sep = ""))
  quit(status = 0)
}

cat(paste("Found", length(csv_files), "CSV file(s)\n"))

# Function to parse filename
parse_filename <- function(filename) {
  basename <- basename(filename)
  
  # Remove .csv extension
  if (!str_detect(basename, "\\.csv$")) {
    return(NULL)
  }
  name <- str_replace(basename, "\\.csv$", "")
  
  # Split by double underscores
  # Format: workload__testworkers__storagetype__partitions__storageengine__paths.csv
  parts <- str_split(name, "__", simplify = TRUE)
  if (length(parts) != 6) {
    return(NULL)
  }
  
  workload <- parts[1]
  workers_str <- parts[2]
  storage_type <- parts[3]
  partitions_str <- parts[4]
  storage_engine <- parts[5]
  paths_str <- parts[6]
  
  # Extract number of workers
  workers <- as.integer(workers_str)
  if (is.na(workers)) {
    return(NULL)
  }
  
  # Extract number of partitions
  partitions <- as.integer(partitions_str)
  if (is.na(partitions)) {
    return(NULL)
  }
  
  # Extract number of paths (remove "paths" suffix)
  paths <- as.integer(str_replace(paths_str, "paths$", ""))
  if (is.na(paths)) {
    return(NULL)
  }
  
  return(list(
    workload = workload,
    workers = workers,
    storage_type = storage_type,
    partitions = partitions,
    storage_engine = storage_engine,
    paths = paths,
    filename = filename
  ))
}

# Function to calculate operations per second from CSV
calculate_ops_per_second <- function(csv_file) {
  tryCatch({
    # Read CSV file as raw text to preserve trailing zeros
    # (R's read.csv converts "133.520" to 133.52, losing the trailing zero)
    lines <- readLines(csv_file)
    if (length(lines) < 2) {
      return(NA)
    }
    
    # Get the last data row (skip header)
    last_line <- lines[length(lines)]
    
    # Parse the CSV row manually
    parts <- strsplit(last_line, ",", fixed = TRUE)[[1]]
    if (length(parts) < 2) {
      return(NA)
    }
    
    # Extract elapsed_time_ms and executed_count as strings
    elapsed_str <- parts[1]
    executed_str <- parts[2]
    
    # Remove dots (thousand separators) to get the actual number
    # Note: dots are thousand separators, not decimal points
    elapsed_ms <- as.numeric(str_replace_all(elapsed_str, "\\.", ""))
    executed_count <- as.numeric(str_replace_all(executed_str, "\\.", ""))
    
    if (is.na(elapsed_ms) || is.na(executed_count) || elapsed_ms <= 0) {
      return(NA)
    }
    
    # Calculate operations per second: executed_count / elapsed_time_ms
    # Note: elapsed_time_ms is in milliseconds, so we convert to seconds
    elapsed_seconds <- elapsed_ms / 1000.0
    ops_per_second <- executed_count / elapsed_seconds
    
    return(ops_per_second)
  }, error = function(e) {
    warning(paste("Error reading", csv_file, ":", e$message))
    return(NA)
  })
}

# Process all CSV files
all_data <- data.frame(
  workload = character(),
  storage_engine = character(),
  storage_type = character(),
  partitions = integer(),
  workers = integer(),
  ops_per_second = numeric(),
  stringsAsFactors = FALSE
)

for (csv_file in csv_files) {
  # Parse filename
  params <- parse_filename(csv_file)
  if (is.null(params)) {
    warning(paste("Warning: Skipping file with unexpected format:", csv_file))
    next
  }
  
  # Calculate operations per second
  ops_per_sec <- calculate_ops_per_second(csv_file)
  if (is.na(ops_per_sec)) {
    warning(paste("Warning: Could not calculate ops/sec for", csv_file))
    next
  }
  
  # Add to data frame
  all_data <- rbind(all_data, data.frame(
    workload = params$workload,
    storage_engine = params$storage_engine,
    storage_type = params$storage_type,
    partitions = params$partitions,
    workers = params$workers,
    ops_per_second = ops_per_sec,
    stringsAsFactors = FALSE
  ))
}

if (nrow(all_data) == 0) {
  stop("Error: No valid data found in CSV files")
}

# Group by workload and storage_engine
grouped <- all_data %>%
  group_by(workload, storage_engine)

# Generate charts
cat(paste("\nGenerating", n_groups(grouped), "chart(s)...\n"))

# Create output directory
dir.create(output_path, showWarnings = FALSE, recursive = TRUE)

# Generate a chart for each workload + storage_engine combination
for (group in group_split(grouped)) {
  workload <- unique(group$workload)
  storage_engine <- unique(group$storage_engine)
  
  # Create storage type labels with partition count
  group$storage_type_label <- paste0(group$storage_type, " (", group$partitions, " partitions)")
  
  # Create a factor for workers to ensure equal spacing
  group$workers_factor <- factor(group$workers, levels = sort(unique(group$workers)))
  
  # Create the plot (convert ops_per_second to thousands)
  p <- ggplot(group, aes(x = workers_factor, y = ops_per_second / 1000, color = storage_type_label, group = storage_type_label)) +
    geom_line(linewidth = 2, alpha = 0.8) +
    geom_point(size = 5, alpha = 0.8) +
    labs(
      x = "Number of Workers",
      y = "Thousand Operations per Second",
      title = paste(workload, "-", storage_engine),
      color = "Storage Type"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 24, face = "bold", hjust = 0.5),
      axis.title = element_text(size = 20),
      axis.text = element_text(size = 18),
      legend.title = element_text(size = 19, face = "bold"),
      legend.text = element_text(size = 18),
      legend.position = "right",
      panel.grid.major = element_line(color = "gray90", linewidth = 0.5),
      panel.grid.minor = element_line(color = "gray95", linewidth = 0.25),
      plot.margin = margin(20, 20, 20, 20)
    ) +
    scale_color_brewer(palette = "Set1") +
    scale_x_discrete() +
    scale_y_continuous(
      expand = expansion(mult = c(0, 0.15)), 
      limits = c(0, NA),
      breaks = pretty_breaks(n = 10)
    )
  
  # Save chart
  safe_workload <- str_replace_all(workload, "[^\\w\\-_]", "_")
  safe_engine <- str_replace_all(storage_engine, "[^\\w\\-_]", "_")
  output_file <- file.path(output_path, paste(safe_workload, safe_engine, "png", sep = "."))
  
  ggsave(output_file, plot = p, width = 10, height = 4, dpi = 300, bg = "white")
  
  cat(paste("Generated chart:", output_file, "\n"))
}

cat(paste("\nAll charts saved to:", output_path, "\n"))
